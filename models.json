{
  "my-example": {
    "eval_steps": 100,
    "max_steps": 1000,
    "save_steps": 100
  },
  "Qwen/Qwen2-1.5B-Instruct": {
    "max_steps": 3000
  },
  "princeton-nlp/Sheared-LLaMA-1.3B": {
    "max_steps": 3000
  },
  "defog/llama-3-sqlcoder-8b": {
    "max_steps": 1500
  },
  "unsloth/SmolLM-1.7B": {
    "max_steps": 2000
  },
  "unsloth/Qwen2.5-1.5B": {
    "max_steps": 4000
  },
  "Xenova/tiny-random-Phi3ForCausalLM": {
    "max_steps": 25000
  },
  "NousResearch/Genstruct-7B": {
    "max_steps": 1500
  },
  "unsloth/Qwen2.5-0.5B": {
    "max_steps": 5000
  },
  "princeton-nlp/Sheared-LLaMA-1.3B": {
    "max_steps": 7000
  },
  "katuni4ka/tiny-random-qwen1.5-moe": {
    "max_steps": 9000
  },
  "Qwen/Qwen2.5-7B-Instruct": {
    "max_steps": 3000
  },
  "fxmarty/tiny-random-GemmaForCausalLM": {
    "max_steps": 2500
  },
  "defog/llama-3-sqlcoder-8b": {
    "max_steps": 2000
  },
  "Intel/neural-chat-7b-v3-3": {
    "eval_steps": 100,
    "max_steps": 700,
    "save_steps": 100
  },
  "heegyu/WizardVicuna2-13b-hf": {
    "eval_steps": 100,
    "max_steps": 700,
    "save_steps": 100
  },
  "MLP-KTLim/llama-3-Korean-Bllossom-8B": {
    "max_steps": 1000
  },
  "tokyotech-llm/Llama-3-Swallow-8B-v0.1": {
    "max_steps": 1500
  },
  "unsloth/SmolLM2-135M": {
    "max_steps": 5000
  },
  "TitanML/tiny-mixtral": {
    "max_steps": 8000
  },
  "unsloth/SmolLM-135M": {
    "max_steps": 7000
  },
  "unsloth/Qwen2.5-Math-1.5B": {
    "max_steps": 2000
  },
  "numind/NuExtract-v1.5": {
    "max_steps": 2000
  },
  "echarlaix/tiny-random-PhiForCausalLM": {
    "max_steps": 50000
  },
  "unsloth/Mistral-Nemo-Base-2407": {
    "max_steps": 2500
  },
  "NousResearch/Yarn-Solar-10b-64k": {
    "eval_steps": 100,
    "max_steps": 800,
    "save_steps": 100
  },
  "fxmarty/really-tiny-falcon-testing": {
    "flash_attention": false,
    "max_steps": 25000
  },
  "unsloth/Mistral-Nemo-Instruct-2407": {
    "gradient_checkpointing": true,
    "gradient_accumulation_steps": 2
  },
  "tiiuae/falcon-7b": {
    "flash_attention": false
  },
  "tiiuae/falcon-mamba-7b": {
    "flash_attention": false,
    "gradient_checkpointing": true,
    "gradient_accumulation_steps": 2
  },
  "tiiuae/falcon-rw-1b": {
    "flash_attention": false
  },
  "EleutherAI/gpt-neo-1.3B": {
    "flash_attention": false,
    "gradient_accumulation_steps": 4,
    "gradient_checkpointing": true,
    "gradient_clipping": 1.0,
    "group_by_length": false,
    "learning_rate": 0.00005,
    "load_in_4bit": true,
    "load_in_8bit": true,
    "lora_alpha": 32,
    "lora_r": 16,
    "micro_batch_size": 2,
    "tf32": false,
    "weight_decay": 0.01,
    "xformers_attention": true,
    "use_cache": false,
    "special_tokens": {
      "pad_token": "<|endoftext|>"
    }
  },
  "EleutherAI/gpt-neo-125m": {
    "flash_attention": false,
    "gradient_accumulation_steps": 4,
    "gradient_checkpointing": true,
    "gradient_clipping": 1.0,
    "group_by_length": false,
    "learning_rate": 0.00005,
    "load_in_4bit": true,
    "load_in_8bit": true,
    "lora_alpha": 32,
    "lora_r": 16,
    "micro_batch_size": 2,
    "tf32": false,
    "weight_decay": 0.01,
    "xformers_attention": true,
    "use_cache": false,
    "special_tokens": {
      "pad_token": "<|endoftext|>"
    }
  },
  "NousResearch/CodeLlama-13b-hf": {
    "flash_attention": false
  },
  "NousResearch/CodeLlama-13b-hf-flash": {
    "flash_attention": false
  },
  "NousResearch/CodeLlama-7b-hf": {
    "flash_attention": false
  },
  "NousResearch/CodeLlama-7b-hf-flash": {
    "flash_attention": false
  },
  "bigscience/bloom-560m": {
    "flash_attention": false
  },
  "bigscience/bloomz-560m": {
    "flash_attention": false
  },
  "NousResearch/Yarn-Llama-2-13b-64k": {
    "flash_attention": false,
    "max_steps": 250
  },
  "NousResearch/Yarn-Llama-2-7b-64k": {
    "flash_attention": false
  },
  "katuni4ka/tiny-random-codegen2": {
    "flash_attention": false,
    "sequence_len": 1024
  },
  "samoline/9c3101fe-8bc7-4dad-9c9a-edfaacfe28fe": {
    "max_steps": 50,
    "num_epochs": 1
  },
  "dunzhang/stella_en_1.5B_v5": {
    "flash_attention": false
  },
  "NousResearch/Yarn-Llama-2-13b-128k": {
    "flash_attention": false
  },
  "NousResearch/Yarn-Llama-2-7b-128k": {
    "flash_attention": false
  }
}
