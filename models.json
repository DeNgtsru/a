{
  "unsloth/Mistral-Nemo-Instruct-2407": {
    "gradient_checkpointing": true,
    "gradient_accumulation_steps": 2
  },
  "tiiuae/falcon-7b": {
    "flash_attention": false
  },
  "tiiuae/falcon-mamba-7b": {
    "flash_attention": false,
    "gradient_checkpointing": true,
    "gradient_accumulation_steps": 2
  },
  "tiiuae/falcon-rw-1b": {
    "flash_attention": false
  },
  "EleutherAI/gpt-neo-1.3B": {
    "early_stopping_patience": "null",
    "flash_attention": false,
    "gradient_accumulation_steps": 4,
    "gradient_checkpointing": true,
    "gradient_clipping": 1.0,
    "group_by_length": false,
    "learning_rate": 0.00005,
    "load_in_4bit": true,
    "load_in_8bit": true,
    "lora_alpha": 32,
    "lora_r": 16,
    "micro_batch_size": 2,
    "tf32": false,
    "weight_decay": 0.01,
    "xformers_attention": true,
    "use_cache": false,
    "special_tokens": {
      "pad_token": "<|endoftext|>"
    }
  },
  "EleutherAI/gpt-neo-125m": {
    "early_stopping_patience": "null",
    "flash_attention": false,
    "gradient_accumulation_steps": 4,
    "gradient_checkpointing": true,
    "gradient_clipping": 1.0,
    "group_by_length": false,
    "learning_rate": 0.00005,
    "load_in_4bit": true,
    "load_in_8bit": true,
    "lora_alpha": 32,
    "lora_r": 16,
    "micro_batch_size": 2,
    "tf32": false,
    "weight_decay": 0.01,
    "xformers_attention": true,
    "use_cache": false,
    "special_tokens": {
      "pad_token": "<|endoftext|>"
    }
  },
  "NousResearch/CodeLlama-13b-hf": {
    "flash_attention": false
  },
  "NousResearch/CodeLlama-13b-hf-flash": {
    "flash_attention": false
  },
  "NousResearch/CodeLlama-7b-hf": {
    "flash_attention": false
  },
  "NousResearch/CodeLlama-7b-hf-flash": {
    "flash_attention": false
  },
  "bigscience/bloom-560m": {
    "flash_attention": false
  },
  "bigscience/bloomz-560m": {
    "flash_attention": false
  },
  "NousResearch/Yarn-Llama-2-13b-64k": {
    "flash_attention": false
  },
  "NousResearch/Yarn-Llama-2-7b-64k": {
    "flash_attention": false
  },
  "katuni4ka/tiny-random-codegen2": {
    "flash_attention": false
  },
  "samoline/9c3101fe-8bc7-4dad-9c9a-edfaacfe28fe": {
    "max_steps": 50,
    "num_epochs": 1
  },
  "dunzhang/stella_en_1.5B_v5": {
    "flash_attention": false
  },
  "NousResearch/Yarn-Llama-2-13b-128k": {
    "flash_attention": false
  },
  "fxmarty/really-tiny-falcon-testing": {
    "flash_attention": false
  }
}
